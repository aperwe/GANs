{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks tutorial\n",
    "based on tutorial by Siraj Raval:\n",
    "https://www.youtube.com/watch?v=0VPQHbMvGzg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf #machine learning\n",
    "import numpy as np #matrix math\n",
    "import datetime #logging the time for model checkpoints and training\n",
    "import matplotlib.pyplot as plt #visualize results\n",
    "%matplotlib inline\n",
    "\n",
    "#Step 1 - Collect dataset\n",
    "#MNIST - handwritten character data ~50k training and validation images + labels, 10k testing.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#will ensure that the correct data has been downloaded to your\n",
    "#local training folder and then unpack that data to return a dictionary of DataSet instances.\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    # First convolutional and pool layers\n",
    "    # These search for 32 different 5x5 pixel features\n",
    "    #We'll start off by passing the image through a convolutional layer.\n",
    "    #First, we create our weight and bias variables through tf.get_variable.\n",
    "    #Our first weight matrix (or filter) will be of size 5x5 and will have an output depth of 32.\n",
    "    #It will be randomly initialized from a normal distribution\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    #tf.constant_init generates tensors with constant values.\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer = tf.constant_initializer(0))\n",
    "    #tf.nn.conv2d() is the Tensorflow's function for a common convolution.\n",
    "    #It takes in 4 arguments. The first is the input volume (our 28 x 28 x 1 image in this case).\n",
    "    #The next argument is the filter/weight matrix. Finally, you can also change the stride and\n",
    "    #padding of the convolution. Those two values affect the dimensions of the output volume.\n",
    "    #\"SAME\" tries to pad evenly left and right, but if the amount of columns to be added is odd,\n",
    "    #it will add the extra column to the right,\n",
    "    #strides = [batch, height, width, channels]\n",
    "    d1 = tf.nn.conv2d(input = x_image, filter = d_w1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    #add the bias\n",
    "    dl = d1 + d_b1\n",
    "    #squash with nonlinearity (ReLU)\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    #An average pooling layer performs down-sampling by dividing the input into\n",
    "    #rectangular pooling regions and computing the average of each region\n",
    "    #It returns the averages for the pooling regions\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    #As with any convolutional neural network ,this module is repeated\n",
    "    # Second convolutional and pool layers\n",
    "    # These search for 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer = tf.constant_initalizer(0))\n",
    "    d2 = tf.nn.conv2d(input = d1, filter = d_w2, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    #And then followed by a series of fully connected layers.\n",
    "    #First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initalizer = tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "    \n",
    "    #The last fully-connected layer holds the output, such as the class scores.\n",
    "    # Second fully connected layer\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer = tf.constant_initializer(0))\n",
    "    \n",
    "    #At the end of the network, we do a final matrix multiply and return the activation value.\n",
    "    #For those of you comfortable with CNNs, this is just a simple binary classifier. Nothing fancy.\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    # d4 dimensions: batch_size x 1\n",
    "    \n",
    "    return d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the generator When it's called, it starts by creating a batch of random noise from the latent space z, then passes it through a hanful of convolutions to produce a 28 x 28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can think of the generator as being a kind of reverse ConvNet. With CNNs, the goal is to\n",
    "#transform a 2- or 3-dimensional matrix of pixel values into a single probability. A generator,\n",
    "#however, seeks to take a d-dimensional noise vector and upsample it to become a 28 x 28 image.\n",
    "#ReLUs are then used to stabilize the outputs of each layer.\n",
    "#Example of CNN blocks http://cs231n.github.io/convolutional-networks/#fc\n",
    "\n",
    "#It takes random inputs, and eventually mapping them down to a [1, 28, 28] pixel to match the MNIS\n",
    "#We begin by generating a dense 14x14 set of values, and then run through a handful of filters\n",
    "#of varying sizes and numbers of channels.\n",
    "#weight matrices get progressively smaller\n",
    "\n",
    "def generator(batch_size, z_dim):\n",
    "    z = tf.truncated_normal([batch_size, z_dim], mean = 0, stddev = 1, name = 'z')\n",
    "    #First deconv block\n",
    "    #3136 = 28 * 28 * 4\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype = tf.float32, initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype = tf.float32, initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initialier = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon = 1e-5, scope = 'bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "    \n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype = tf.float32, initializer = tf.truncated_normal_initializer(stddev = 0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer = tf.truncated_normal_initializer(stddev = 0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon = 1e-5, scope = 'bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "    \n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype = tf.float32, initializer = tf.truncated_normal_initializer(stddev = 0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer = tf.truncated_normal_initializer(stddev = 0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # No batch normalization at the final layer, but we do add\n",
    "    # a sigmoid activator to make the generated images crisper.\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    \n",
    "    return g4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up our losses and optimizers.\n",
    "$$c = \\nabla \\phi \\sqrt{a^2 + b^2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
